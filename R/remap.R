#' Build separate models for mapping multiple regions.
#'
#' Separate models are built for each given region and combined into one S3
#' object that can be used to predict on new data using generic function
#' predict(). If a model fails for a region, a warning is given but the modeling
#' process will continue.
#'
#'
#' @param data An sf data frame with longitude, latitude, and columns required
#' for modeling.
#' @param lon Name of longitude column (no quotes).
#' @param lat Name of latitude column (no quotes).
#' @param model_function A function that can take a subset of 'data' and
#' output a model that can be used to predict new values when passed to generic
#' function predict().
#' @param buffer A buffer zone around each region in km where data is included
#' in the data used to build models for each region. (Can be a named vector
#' with different values for each unique 'region_id' in 'region'.)
#' @param min_n The minimum number of observations to use when building a model.
#' If there are not enough observations in the region and buffer, then the
#' closest min_n observations are used. No minimum if set to 0.
#' @param regions An sf dataframe with polygon geometry.
#' @param region_id Optional name of column in 'regions' that contains the id
#' that each region belongs to (no quotes). If null, it will be assumed that
#' each polygon is its own region (no regions have more than one polygon).
#' @param distances An optional matrix of distances between 'data' and 'regions'
#' generated by redist() function (calculated internally if not
#' provided).
#' @param progress If true, a text progress bar is printed to the console.
#' @param keep_data If true, extra data is included in the output object. Extra
#' data is 'data', 'distances', and 'data_indices', (see output description).
#' @param ... Extra arguments to pass to 'model_function' function.
#'
#' @return A \emph{remap} S3 object containing:
#' \describe{
#'   \item{\emph{models}}{A list of models containing a model output by
#'   'model_function' for each region.}
#'   \item{\emph{regions}}{'regions' object passed to the function (used for
#'   prediction).}
#'   \item{\emph{region_id}}{'region_id' object passed to the function (used for
#'   prediction).}
#'   \item{\emph{call}}{Shows the parameters that were passed to the function.}
#'   \item{\emph{data}}{'data' object passed to the function
#'   ('keep_data' = TRUE).}
#'   \item{\emph{distances}}{Distances returned by internal call of
#'   redist() function ('keep_data' = TRUE).}
#'   \item{\emph{data_indices}}{A list of indices of rows of 'data' that were
#'   used to build each regional model ('keep_data' = TRUE).}
#' }
#'
#' @seealso
#'   \code{\link{predict.remap}} - used for predicting on new data.
#'   \code{\link{redist}} - used for building models within a buffer.
#'
#'
#' @export
remap <- function(data, lon, lat, model_function, buffer, min_n = 0,
                  regions, region_id = NULL, distances = NULL,
                  progress = TRUE, keep_data = FALSE, ...) {

  # Check input
  # ============================================================================
  if (!"data.frame" %in% class(data)) stop("data must be class 'data.frame'")
  if (!"sf" %in% class(regions)) stop("regions must be class 'sf'")
  if (!is.null(distances) && nrow(data) != nrow(distances)) {
    stop("Rows in data must be same length as row in distances.")
  }

  if (!tryCatch(is.character(lon), error = function(e) FALSE)) {
    lon <- deparse(substitute(lon))
  }
  if (!tryCatch(is.character(lat), error = function(e) FALSE)) {
    lat <- deparse(substitute(lat))
  }

  if (!missing(region_id) &&
      !tryCatch(is.character(region_id), error = function(e) FALSE)) {
    region_id <- deparse(substitute(region_id))
  }

  # Find distances between the data and each region
  # ============================================================================
  if (is.null(distances)) {
    if(progress) cat("Finding distances...\n")
    if (missing(region_id)) {
      distances <- redist(data, lon = lon, lat = lat,
                          regions = regions, progress = progress)
    } else {
      distances <- redist(data, lon = lon, lat = lat,
                          regions = regions, region_id = region_id,
                          progress = progress)
    }
  }

  id_list <- colnames(distances)

  # Check buffer
  # ===========================================================================
  if(length(buffer) == 1) {
    buffer <- rep(buffer, length(id_list))
    names(buffer) <- id_list
  } else if (!all(names(buffer) %in% id_list)) {
    stop("'buffer' values must have names equal to unique values",
         "in the 'region_id' column of 'regions'.")
  }

  # Reduce areas to places that have values present
  # ===========================================================================
  keep <-  apply(distances, 2, function(x) sum(x == 0 & !is.na(x)) > 0)
  id_list <- id_list[keep]
  buffer <- buffer[id_list]
  distances <- distances[, id_list]
  regions <- regions[regions[[region_id]] %in% id_list, ]

  # Find models for each region id
  # ============================================================================
  models <- list()
  data_indices <- list()

  # add progress bar
  if (progress) {
    cat("\nBuilding models...\n")
    pb <- utils::txtProgressBar(min = 0, max = length(id_list), style = 3)
    i <- 1
  }

  for (id in id_list) {
    # get indices for building model
    indices <- which(distances[, id] < buffer[[id]])
    if (length(indices) < min_n) {
      indices <- order(distances[, id])[1:min_n]
    }

    # try building a model and warn if one fails
    models[[id]] <- tryCatch({
      model_function(data[indices, ], ...)
    },
    error = function(e) {
      warning("Error in model for region ", id, ":\n", e)
      NULL
    })

    # Save data row indices used for building each model if keeping data
    if (keep_data) data_indices[[id]] <- indices

    # update progress bar
    if (progress) {
      utils::setTxtProgressBar(pb, i)
      i <- i + 1
    }
  }

  if (progress) cat("\n")

  # remove regions where model failed
  models <- models[sapply(models, function(x) !is.null(x))]
  id_list <- id_list[id_list %in% names(models)]
  regions <- regions[regions[[region_id]] %in% id_list, ]


  # Create output
  # ============================================================================
  output <- list(models = models, lon = lon, lat = lat, regions = regions,
                 region_id = region_id, call = match.call())

  if (keep_data) {
    output[["data"]] <- data
    output[["distances"]] <- distances
    output[["data_indices"]] <- data_indices
  }

  class(output) <- "remap"
  return(output)
}





#` \emph{remap} prediction function.
#'
#' Make predictions given a set of data and smooths predictions between regions.
#' If an observation is outside of all regions and smoothing distances, the
#' closest region will be used to predict.
#'
#' @param object \emph{} S3 object output from sboost.
#' @param data An sf dataframe with point geometry.
#' @param smooth The distance in km within a region where a smooth transition
#' to the next region starts. (Can be a named vector with different values for
#' each unique object$region_id' in 'object$region'.)
#' @param distances An optional matrix of distances between 'data' and
#' 'object$regions' generated by redist() function (calculated
#' internally if not provided).
#' @param threads Number of threads for parallel computing. 'threads' above
#' default of 1 will require more memory.
#' @param progress If true, a text progress bar is printed to the console.
#' @param ... Arguments to pass to individual model prediction functions.
#'
#' @return Predictions in the form of a vector.
#'
#' @seealso \code{\link{remap}} building a regional model.
#'
#' @export
predict.remap <- function(object, data, smooth, distances = NULL,
                                   threads = 1, progress = TRUE, ...) {

  # Check input
  # ============================================================================
  if (!"data.frame" %in% class(data)) stop("data must be class 'data.frame'")
  id_list <- names(object$models)

  # Check smooth
  # ===========================================================================
  if(length(smooth) == 1) {
    smooth <- rep(smooth, length(id_list))
    names(smooth) <- id_list
  } else if (!all(names(smooth) %in% id_list)) {
    stop("'smooth' values must have names equal to unique values",
         "in the 'object$region_id' column of 'object$regions'.")
  }
  smooth <- smooth[id_list]

  # Find distances between the data and each region
  # ============================================================================
  if (is.null(distances)) {
    if(progress) cat("Finding distances...\n")
    distances <- redist(data, lon = object$lon, lat = object$lat,
                        max_dist = max(smooth),
                        regions = object$regions,
                        region_id = object$region_id,
                        progress = progress)
  }
  distances <- distances[, id_list]

  # make sure all values have a distance within 'smooth' of a region
  distances[t(apply(distances, 1, function(x) {
    x >= smooth & x == min(x, na.rm = TRUE) & !is.na(x)
  }))] <- 0

  # Make predictions and smooth to final output
  # ============================================================================
  output <- rep(as.numeric(NA), nrow(data))
  weightsum <- rep(0, nrow(data))

  # add progress bar
  if (progress) {
    cat("\nPredicting...\n")
    pb <- utils::txtProgressBar(min = 0, max = length(id_list), style = 3)
    i <- 1
  }

  # do predictions in parallel if specified
  if (threads > 1) {
    clusters <- parallel::makeCluster(threads)

    parallel::clusterExport(clusters,
                            c("object", "data", "distances", "smooth",
                              unlist(lapply(search(), function(x) {
                                objects(x, pattern = "predict")
                              }))),
                            envir = environment())

    pred_list <- parallel::parLapply(
      clusters,
      as.list(id_list),
      function(id) {
        indices <- which(distances[, id] < smooth[[id]] &
                           !is.na(distances[, id]))

        stats::predict(object$models[[id]], data[indices, ])
      }
    )

    parallel::stopCluster(clusters)

    names(pred_list) <- id_list
  }

  # use running weighted average
  #   \mew_1 = x_1
  #   \mew_k = \mew_{k-1} + (w_k / \sum_1^k{w_i}) * (x_k - \mew_{k-1})
  for (id in id_list) {
    # only consider values within smoothing range
    indices <- distances[, id] < smooth[[id]] & !is.na(distances[, id])

    # make predictions
    if (threads > 1) {
      preds <- pred_list[[id]]
    } else {
      preds <- stats::predict(object$models[[id]], data[indices, ])
    }

    # update weights
    weight <- ((smooth[[id]] - distances[indices, id]) / smooth[[id]])^2
    weightsum[indices] <- weightsum[indices] + weight

    # update output (k > 1)
    output[indices] <- output[indices] +
      (weight / weightsum[indices]) * (preds - output[indices])

    # update output (k == 1)
    starting <- indices & is.na(output)
    output[starting] <- preds[starting[indices]]

    # update progress bar
    if (progress) {
      utils::setTxtProgressBar(pb, i)
      i <- i + 1
    }
  }

  if (progress) cat("\n")

  return(output)
}
















